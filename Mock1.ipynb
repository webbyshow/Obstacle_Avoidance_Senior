{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record Video using Laptop Camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record and save video to the specific path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "source  = r\"c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\"\n",
    "folder = os.listdir(r\"c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\")\n",
    "save_path = os.path.join(source,folder[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording... Press 'q' to stop and save the video.\n",
      "Exiting and saving video...\n",
      "The video was saved successfully: c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\mock1.avi\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "# Define the source folder\n",
    "source = r\"c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\"\n",
    "\n",
    "# Check if the source folder exists\n",
    "if not os.path.exists(source):\n",
    "    print(f\"Source folder does not exist: {source}\")\n",
    "    exit()\n",
    "\n",
    "# List folders inside the source directory\n",
    "folder = os.listdir(source)\n",
    "\n",
    "# Ensure there is at least one folder\n",
    "if len(folder) == 0:\n",
    "    print(f\"No subfolders found in: {source}\")\n",
    "    exit()\n",
    "\n",
    "# Join the source path with the first folder\n",
    "save_path = os.path.join(source, folder[0])\n",
    "\n",
    "# Ensure save_path is a valid directory\n",
    "if not os.path.isdir(save_path):\n",
    "    print(f\"Save path is not a valid directory: {save_path}\")\n",
    "    exit()\n",
    "\n",
    "# Define the output video file path\n",
    "video_file = os.path.join(save_path, 'mock1.avi')\n",
    "\n",
    "# Open the default camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if the camera opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "    exit()\n",
    "\n",
    "# Define the codec and create a VideoWriter object\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter(video_file, fourcc, 20.0, (frame_width, frame_height))\n",
    "\n",
    "print(\"Recording... Press 'q' to stop and save the video.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame.\")\n",
    "        break\n",
    "\n",
    "    out.write(frame)  # Save each frame to the video file\n",
    "    cv2.imshow('Recording', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print(\"Exiting and saving video...\")\n",
    "        break\n",
    "\n",
    "# Release the camera and video writer\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Check if the video file exists after saving\n",
    "if os.path.exists(video_file):\n",
    "    print(f\"The video was saved successfully: {video_file}\")\n",
    "else:\n",
    "    print(f\"Failed to save the video: {video_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing the recorded video. Press 'q' to quit.\n",
      "End of video.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Path to the recorded video\n",
    "video_file = r\"c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\mock1.avi\"\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open video file {video_file}\")\n",
    "    exit()\n",
    "\n",
    "print(\"Playing the recorded video. Press 'q' to quit.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of video.\")\n",
    "        break\n",
    "\n",
    "    # Display the video frame\n",
    "    cv2.imshow('Playback', frame)\n",
    "\n",
    "    # Exit playback on 'q' key press\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        print(\"Exiting playback...\")\n",
    "        break\n",
    "\n",
    "# Release the video capture and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraced frames from saved video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video FPS: 20\n",
      "Extracting frames...\n",
      "Saved: c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\extracted_frames\\frame_0000.jpg\n",
      "Saved: c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\extracted_frames\\frame_0001.jpg\n",
      "Saved: c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\extracted_frames\\frame_0002.jpg\n",
      "Saved: c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\extracted_frames\\frame_0003.jpg\n",
      "Saved: c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\extracted_frames\\frame_0004.jpg\n",
      "Saved: c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\extracted_frames\\frame_0005.jpg\n",
      "Saved: c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\extracted_frames\\frame_0006.jpg\n",
      "Saved: c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\extracted_frames\\frame_0007.jpg\n",
      "Saved: c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\extracted_frames\\frame_0008.jpg\n",
      "Saved: c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\extracted_frames\\frame_0009.jpg\n",
      "Saved: c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\extracted_frames\\frame_0010.jpg\n",
      "Saved: c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\extracted_frames\\frame_0011.jpg\n",
      "Saved: c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\extracted_frames\\frame_0012.jpg\n",
      "Saved: c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\extracted_frames\\frame_0013.jpg\n",
      "Saved: c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\extracted_frames\\frame_0014.jpg\n",
      "End of video.\n",
      "Total frames saved: 15\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Path to the recorded video\n",
    "video_file = r\"c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\mock1.avi\"\n",
    "\n",
    "# Directory to save extracted frames\n",
    "output_folder = r\"c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\extracted_frames\"\n",
    "\n",
    "# Desired FPS for frame extraction\n",
    "desired_fps = 1  # Example: 1 frame per second\n",
    "\n",
    "# Ensure output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open video file {video_file}\")\n",
    "    exit()\n",
    "\n",
    "# Get the video's FPS\n",
    "video_fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "print(f\"Video FPS: {video_fps}\")\n",
    "\n",
    "# Calculate the frame interval for the desired FPS\n",
    "frame_interval = video_fps // desired_fps\n",
    "\n",
    "frame_count = 0\n",
    "saved_count = 0\n",
    "\n",
    "print(\"Extracting frames...\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of video.\")\n",
    "        break\n",
    "\n",
    "    # Save frames based on the calculated interval\n",
    "    if frame_count % frame_interval == 0:\n",
    "        image_path = os.path.join(output_folder, f\"frame_{saved_count:04d}.jpg\")\n",
    "        cv2.imwrite(image_path, frame)\n",
    "        print(f\"Saved: {image_path}\")\n",
    "        saved_count += 1\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "# Release the video capture\n",
    "cap.release()\n",
    "print(f\"Total frames saved: {saved_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['frame_0000.jpg', 'frame_0001.jpg', 'frame_0002.jpg', 'frame_0003.jpg', 'frame_0004.jpg', 'frame_0005.jpg', 'frame_0006.jpg', 'frame_0007.jpg', 'frame_0008.jpg', 'frame_0009.jpg', 'frame_0010.jpg', 'frame_0011.jpg', 'frame_0012.jpg', 'frame_0013.jpg', 'frame_0014.jpg', 'frame_0015.jpg', 'frame_0016.jpg', 'frame_0017.jpg', 'frame_0018.jpg', 'frame_0019.jpg', 'frame_0020.jpg', 'frame_0021.jpg', 'frame_0022.jpg', 'frame_0023.jpg']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(os.path.join(save_path,'extracted_frames')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the first 5th image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying the first five extracted frames...\n",
      "Displaying: c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\extracted_frames\\frame_0000.jpg\n",
      "Displaying: c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\extracted_frames\\frame_0001.jpg\n",
      "Displaying: c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\extracted_frames\\frame_0002.jpg\n",
      "Displaying: c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\extracted_frames\\frame_0003.jpg\n",
      "Displaying: c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\extracted_frames\\frame_0004.jpg\n",
      "Done displaying the first five frames.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Path to the folder containing extracted frames\n",
    "frames_folder = r\"c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\extracted_frames\"\n",
    "\n",
    "# List all image files in the folder\n",
    "image_files = sorted([f for f in os.listdir(frames_folder) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
    "\n",
    "# Display the first five images\n",
    "print(\"Displaying the first five extracted frames...\")\n",
    "\n",
    "for i, image_file in enumerate(image_files[:5]):  # Limit to the first 5 images\n",
    "    image_path = os.path.join(frames_folder, image_file)\n",
    "    \n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    if image is None:\n",
    "        print(f\"Failed to load image: {image_path}\")\n",
    "        continue\n",
    "    \n",
    "    # Display the image\n",
    "    cv2.imshow(f\"Frame {i + 1}\", image)\n",
    "    print(f\"Displaying: {image_path}\")\n",
    "    \n",
    "    # Wait for 500 milliseconds before showing the next image\n",
    "    cv2.waitKey(500)  \n",
    "\n",
    "# Close all image windows\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Done displaying the first five frames.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use YOLOv3 to detect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\darknet\\darknet_importer.cpp:210: error: (-212:Parsing error) Failed to open NetParameter file: C:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_two_cam_26_Nov\\yolov3\\yolov3.cfg in function 'cv::dnn::dnn4_v20240521::readNetFromDarknet'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m labels_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mwebin\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mFor Senior Video\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMock_two_cam_26_Nov\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124myolov3\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcoco.names\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Load YOLO model\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m net \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mdnn\u001b[38;5;241m.\u001b[39mreadNetFromDarknet(config_path, weights_path)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Use GPU (optional)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Load class labels\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(labels_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\darknet\\darknet_importer.cpp:210: error: (-212:Parsing error) Failed to open NetParameter file: C:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_two_cam_26_Nov\\yolov3\\yolov3.cfg in function 'cv::dnn::dnn4_v20240521::readNetFromDarknet'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Paths to YOLOv3 files\n",
    "weights_path = r\"c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\yolov3\\yolov3.weights\"\n",
    "config_path = r\"c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\yolov3\\yolov3.cfg\"\n",
    "labels_path = r\"c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\yolov3\\coco.names\"\n",
    "\n",
    "# Load class labels\n",
    "with open(labels_path, \"r\") as f:\n",
    "    labels = f.read().strip().split(\"\\n\")\n",
    "\n",
    "# Set random colors for each label\n",
    "colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255)] * len(labels)\n",
    "\n",
    "# Load YOLOv3 network\n",
    "net = cv2.dnn.readNetFromDarknet(config_path, weights_path)\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "\n",
    "\n",
    "# Path to the folder containing extracted frames\n",
    "frames_folder = r\"c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\extracted_frames\"\n",
    "\n",
    "# Output folder for detected images\n",
    "output_folder = r\"c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\detected_frames\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# List all image files in the folder\n",
    "image_files = sorted([f for f in os.listdir(frames_folder) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
    "\n",
    "print(\"Applying YOLOv3 to frames...\")\n",
    "\n",
    "for image_file in image_files[:]:  # Process only the first five frames\n",
    "    image_path = os.path.join(frames_folder, image_file)\n",
    "    image = cv2.imread(image_path)\n",
    "    (H, W) = image.shape[:2]\n",
    "\n",
    "    # Prepare the image for YOLOv3\n",
    "    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    layer_outputs = net.forward(output_layers)\n",
    "\n",
    "    # Initialize lists for detected bounding boxes, confidences, and class IDs\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "\n",
    "    for output in layer_outputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id = int(scores.argmax())\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:  # Confidence threshold\n",
    "                box = detection[0:4] * [W, H, W, H]\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    # Apply Non-Maxima Suppression\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "    # Draw bounding boxes and labels on the image\n",
    "    if len(indices) > 0:\n",
    "        for i in indices.flatten():\n",
    "            (x, y, w, h) = boxes[i]\n",
    "            color = colors[class_ids[i] % len(colors)]\n",
    "            label = f\"{labels[class_ids[i]]}: {confidences[i]:.2f}\"\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(image, label, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    # Save the detected image\n",
    "    detected_path = os.path.join(output_folder, image_file)\n",
    "    cv2.imwrite(detected_path, image)\n",
    "    print(f\"Processed and saved: {detected_path}\")\n",
    "\n",
    "    # Display the image (optional)\n",
    "    cv2.imshow(\"YOLO Detection\", image)\n",
    "    cv2.waitKey(500)  # Show each image for 500 milliseconds\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Object detection completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do a smoother video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoother video saved as c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\smooth_video.avi\n"
     ]
    }
   ],
   "source": [
    "# WaitKey with lower delay for smoother playback\n",
    "cv2.waitKey(1)  # Use 1ms delay instead of 25ms for near real-time playback\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the video\n",
    "video_file = r\"c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\mock1.avi\"\n",
    "cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "# Define codec and create a VideoWriter object for the smoother video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "output_file = r\"c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\smooth_video.avi\"\n",
    "fps = 60  # Target higher FPS\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "out = cv2.VideoWriter(output_file, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "ret, prev_frame = cap.read()\n",
    "prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "while True:\n",
    "    ret, curr_frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert current frame to grayscale\n",
    "    curr_gray = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate optical flow between frames\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, curr_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "    # Interpolate frames\n",
    "    interpolated_frame = cv2.addWeighted(prev_frame, 0.5, curr_frame, 0.5, 0)\n",
    "    for t in np.linspace(0, 1, 2):  # Add intermediate frames (2x FPS)\n",
    "        temp_frame = cv2.addWeighted(prev_frame, 1 - t, curr_frame, t, 0)\n",
    "        out.write(temp_frame)  # Save the interpolated frame\n",
    "\n",
    "    # Write the original frame\n",
    "    out.write(curr_frame)\n",
    "\n",
    "    # Update for next iteration\n",
    "    prev_frame = curr_frame.copy()\n",
    "    prev_gray = curr_gray.copy()\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Smoother video saved as {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\smooth.dispatch.cpp:617: error: (-215:Assertion failed) !_src.empty() in function 'cv::GaussianBlur'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m smoothed_frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mGaussianBlur(curr_frame, (\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m5\u001b[39m), \u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Apply Gaussian Blur\u001b[39;00m\n\u001b[0;32m      2\u001b[0m out\u001b[38;5;241m.\u001b[39mwrite(smoothed_frame)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\smooth.dispatch.cpp:617: error: (-215:Assertion failed) !_src.empty() in function 'cv::GaussianBlur'\n"
     ]
    }
   ],
   "source": [
    "smoothed_frame = cv2.GaussianBlur(curr_frame, (5, 5), 0)  # Apply Gaussian Blur\n",
    "out.write(smoothed_frame)  # Write smoothed frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Path to input video\n",
    "video_file = r\"c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\mock1.avi\"\n",
    "\n",
    "# Path to save the smoother video\n",
    "output_file = r\"c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\smooth_video.avi\"\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "# Define codec and output video writer\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "out = cv2.VideoWriter(output_file, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Process each frame\n",
    "while True:\n",
    "    ret, curr_frame = cap.read()\n",
    "    \n",
    "    # Check if the frame is read correctly\n",
    "    if not ret:\n",
    "        print(\"End of video or failed to read frame.\")\n",
    "        break\n",
    "\n",
    "    # Apply Gaussian Blur to the frame\n",
    "    smoothed_frame = cv2.GaussianBlur(curr_frame, (5, 5), 0)\n",
    "    \n",
    "    # Write the smoothed frame to the output video\n",
    "    out.write(smoothed_frame)\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Smoother video saved as {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing the smooth video. Press 'q' to quit.\n",
      "End of video.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Path to the smooth video\n",
    "smooth_video_file = r\"c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\smooth_video.avi\"\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(smooth_video_file)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open video file {smooth_video_file}\")\n",
    "    exit()\n",
    "\n",
    "print(\"Playing the smooth video. Press 'q' to quit.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Break if the video ends\n",
    "    if not ret:\n",
    "        print(\"End of video.\")\n",
    "        break\n",
    "\n",
    "    # Display the video frame\n",
    "    cv2.imshow(\"Smooth Video\", frame)\n",
    "\n",
    "    # Press 'q' to quit the playback\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        print(\"Exiting playback...\")\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View smooth video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing the smoothed detection video. Press 'q' to quit.\n",
      "End of video.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Path to the smoothed detection video\n",
    "smoothed_detection_video = r\"c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\smooth_video.avi\"\n",
    "\n",
    "# Open the smoothed detection video\n",
    "cap = cv2.VideoCapture(smoothed_detection_video)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open video file {smoothed_detection_video}\")\n",
    "    exit()\n",
    "\n",
    "print(\"Playing the smoothed detection video. Press 'q' to quit.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Break if the video ends\n",
    "    if not ret:\n",
    "        print(\"End of video.\")\n",
    "        break\n",
    "\n",
    "    # Display the video frame\n",
    "    cv2.imshow(\"Smoothed Detection Video\", frame)\n",
    "\n",
    "    # Press 'q' to quit the playback\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        print(\"Exiting playback...\")\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View detected smooth video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying YOLOv3 detection and smoothing...\n",
      "End of video.\n",
      "Smoothed detection video saved as c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\smoothed_detection_video.avi\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Paths to YOLOv3 files\n",
    "weights_path = r\"c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\yolov3\\yolov3.weights\"\n",
    "config_path = r\"c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\yolov3\\yolov3.cfg\"\n",
    "labels_path = r\"c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\yolov3\\coco.names\"\n",
    "\n",
    "# Load class labels\n",
    "with open(labels_path, \"r\") as f:\n",
    "    labels = f.read().strip().split(\"\\n\")\n",
    "\n",
    "# Set random colors for each label\n",
    "colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255)] * len(labels)\n",
    "\n",
    "# Load YOLOv3 network\n",
    "net = cv2.dnn.readNetFromDarknet(config_path, weights_path)\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Path to the video file\n",
    "video_file = r\"c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\mock1.avi\"\n",
    "\n",
    "# Output file for smoothed detection video\n",
    "output_file = r\"c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\smoothed_detection_video.avi\"\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "# Define codec and create a VideoWriter object for the smoother video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "out = cv2.VideoWriter(output_file, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "print(\"Applying YOLOv3 detection and smoothing...\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of video.\")\n",
    "        break\n",
    "\n",
    "    # Prepare the image for YOLOv3\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    layer_outputs = net.forward(output_layers)\n",
    "\n",
    "    # Initialize lists for detected bounding boxes, confidences, and class IDs\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "\n",
    "    for output in layer_outputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id = int(scores.argmax())\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:  # Confidence threshold\n",
    "                box = detection[0:4] * [frame_width, frame_height, frame_width, frame_height]\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    # Apply Non-Maxima Suppression\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "    # Draw bounding boxes and labels on the image\n",
    "    if len(indices) > 0:\n",
    "        for i in indices.flatten():\n",
    "            (x, y, w, h) = boxes[i]\n",
    "            color = colors[class_ids[i] % len(colors)]\n",
    "            label = f\"{labels[class_ids[i]]}: {confidences[i]:.2f}\"\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(frame, label, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    # Apply Gaussian blur for smoothing\n",
    "    smoothed_frame = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "\n",
    "    # Write the smoothed frame with detection to the output video\n",
    "    out.write(smoothed_frame)\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Smoothed detection video saved as {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing the smoothed detection video. Press 'q' to quit.\n",
      "End of video.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Path to the smoothed detection video\n",
    "smoothed_detection_video = r\"c:\\Users\\webin\\OneDrive\\Desktop\\For Senior Video\\Mock_at_26_Nov\\smoothed_detection_video.avi\"\n",
    "\n",
    "# Open the smoothed detection video\n",
    "cap = cv2.VideoCapture(smoothed_detection_video)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open video file {smoothed_detection_video}\")\n",
    "    exit()\n",
    "\n",
    "print(\"Playing the smoothed detection video. Press 'q' to quit.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Break if the video ends\n",
    "    if not ret:\n",
    "        print(\"End of video.\")\n",
    "        break\n",
    "\n",
    "    # Display the video frame\n",
    "    cv2.imshow(\"Smoothed Detection Video\", frame)\n",
    "\n",
    "    # Press 'q' to quit the playback\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        print(\"Exiting playback...\")\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
